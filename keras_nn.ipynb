{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:09:58.364987Z",
     "start_time": "2018-02-20T21:09:56.895132Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neal\\Anaconda3\\envs\\keras\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n",
      "2.1.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Embedding\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print( keras.__version__)\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:09:59.355722Z",
     "start_time": "2018-02-20T21:09:58.366989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2598560, 769)\n",
      "(1925000, 769)\n"
     ]
    }
   ],
   "source": [
    "def getTest(whitewins, blackwins):\n",
    "    test = []\n",
    "    test_l = []\n",
    "    for i in range(whitewins.shape[0]):\n",
    "        if np.random.randn(1)>0.5:\n",
    "            test.append([whitewins[i],blackwins[i]])\n",
    "            test_l.append([1, 0])\n",
    "        else:\n",
    "            test.append([blackwins[i],whitewins[i]])\n",
    "            test_l.append([0, 1])\n",
    "#         temp_test = np.zeros((len(test), 2, input_size))\n",
    "#     for i in range(len(test)):\n",
    "#         first = bitifyFEN(test[i][0])\t\n",
    "#         second = bitifyFEN(test[i][1])\t\n",
    "#         elem = [first,second]\n",
    "#         temp_test[i] = elem\n",
    "    return (np.array(test), np.array(test_l))\n",
    "\n",
    "def getBatchAE(start, size):\n",
    "    global whiteWins \n",
    "    global blackWins \n",
    "    size = size//2\n",
    "    start = start*size\n",
    "\n",
    "    temp1 = np.concatenate((whiteWins[start:start+size],blackWins[start:start+size]),axis=0)\n",
    "    np.random.shuffle(temp1)\n",
    "    return temp1\n",
    "\n",
    "ff = h5py.File(\"raw_chess_data.hdf5\", \"r\")\n",
    "\n",
    "# print(ff.keys())\n",
    "whiteWins2 = ff['white']\n",
    "blackWins2 = ff['black']\n",
    "validation_test, validation_test_l = getTest(whiteWins2[:100000],blackWins2[:100000])\n",
    "print(whiteWins2.shape)\n",
    "print(blackWins2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:09:59.378251Z",
     "start_time": "2018-02-20T21:09:59.358727Z"
    }
   },
   "outputs": [],
   "source": [
    "def getBatchMLP(start, size):\n",
    "    import random\n",
    "    global whiteWins \n",
    "    global blackWins \n",
    "\n",
    "    xR = []\n",
    "    lR = []\n",
    "\n",
    "    for i in range(start,start+size):\n",
    "        if random.random() > 0.5:\n",
    "            elem = [whiteWins[i], blackWins[i]]\n",
    "            elem_l = [1,0]\n",
    "        else:\n",
    "            elem = [blackWins[i], whiteWins[i]]\n",
    "            elem_l = [0,1]\n",
    "        xR.append(elem)\n",
    "        lR.append(elem_l)\n",
    "    return (np.array(xR), np.array(lR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:36:25.898756Z",
     "start_time": "2018-02-20T21:36:25.819657Z"
    }
   },
   "outputs": [],
   "source": [
    "encoding_dim2 = 400\n",
    "\n",
    "encoded2 = Dense(encoding_dim2, activation='selu')(encoded)\n",
    "decoded2 = Dense(encoding_dim, activation='sigmoid')(encoded2)\n",
    "decoded_1 = autoencoder1.layers[-1](decoded2)\n",
    "autoencoder2 = Model(input_img, decoded_1)\n",
    "autoencoder2.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim3 = 200\n",
    "\n",
    "encoded3 = Dense(encoding_dim3, activation='selu')(encoded2)\n",
    "decoded3 = Dense(encoding_dim2, activation='sigmoid')(encoded3)\n",
    "decoded_1 = autoencoder2.layers[-1](decoded2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:52:50.160772Z",
     "start_time": "2018-02-20T21:52:49.963026Z"
    }
   },
   "outputs": [],
   "source": [
    "# do them all at once:\n",
    "dims = [600,400,200,100]\n",
    "input_img = Input(shape=(769,))\n",
    "encoded1 = Dense(dims[0], activation='selu')(input_img)\n",
    "encoded2 = Dense(dims[1], activation='selu')(encoded1)\n",
    "encoded3 = Dense(dims[2], activation='selu')(encoded2)\n",
    "encoded4 = Dense(dims[3], activation='selu')(encoded3)\n",
    "decoded4 = Dense(dims[2], activation='selu')(encoded4)\n",
    "decoded3 = Dense(dims[1], activation='selu')(decoded4)\n",
    "decoded2 = Dense(dims[0], activation='selu')(decoded3)\n",
    "decoded1 = Dense(769, activation='softmax')(decoded2)\n",
    "autoencoder = Model(input_img, decoded1)\n",
    "autoencoder.compile(optimizer='adadelta', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:28:12.487568Z",
     "start_time": "2018-02-20T21:27:56.734135Z"
    }
   },
   "outputs": [],
   "source": [
    "whiteWins = np.random.permutation(whiteWins2[100000:])[:1000000]\n",
    "blackWins = np.random.permutation(blackWins2[100000:])[:1000000]\n",
    "TOTAL_AE = 1000000\n",
    "BS_AE = 25000\n",
    "EPOCHS_AE = 400\n",
    "total_batch = int(TOTAL_AE/BS_AE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:29:23.519193Z",
     "start_time": "2018-02-20T21:29:23.516188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 769)\n"
     ]
    }
   ],
   "source": [
    "# print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T22:06:10.194963Z",
     "start_time": "2018-02-20T21:52:52.668588Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 3s 115us/step - loss: 94.6104\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 84.2459\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 81.3506\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 80.2827\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 79.4486\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 78.9724\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 78.2061\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 78.1314\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 77.8237\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 77.2349\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 76.7317\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 76.6039\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 76.4384\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 75.9733\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 76.1918\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 75.8653\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 75.1589\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 75.3873\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 75.0668\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 74.8381\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 69us/step - loss: 74.4813\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 85us/step - loss: 74.5122\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 74.2850\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 74.2530\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 84us/step - loss: 73.8022\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 73.8346\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 73.3854\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 73.4379\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 73.3945\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 88us/step - loss: 73.1238\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 81us/step - loss: 73.3378\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 73.1965\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 72.8084\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 73.1588\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 72.6804\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 72.9670\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 72.7731\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 72.6277\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 72.4737\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 72.5176\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 72.5627\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 72.3875\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 71.9988\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 72.1748\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 72.0953\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 72.1570\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 71.8145\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 72.1732\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 72.0985\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 71.8280\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 71.5183\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 71.7385\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 89us/step - loss: 71.6889\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 71.4762\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 88us/step - loss: 71.9037\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 85us/step - loss: 71.8520\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 84us/step - loss: 71.3354\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 71.7262\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 71.5936\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 71.5526\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 71.3629\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 71.5550\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 71.4218\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 83us/step - loss: 71.4884\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 71.2550\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 71.3254\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 71.0802\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 71.1667\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 71.2396\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 71.0086\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 71.3170\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 71.2152\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 70.9942\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 71.3050\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 70.8800\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 71.2501\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 69us/step - loss: 71.2019\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 71.0991\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 81us/step - loss: 70.8570\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 71.0275\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 71.1165\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 71.0269\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 81us/step - loss: 70.6258\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 81us/step - loss: 70.8747\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 70.8277\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 70.9464\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 70.5729\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 70.9627\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 70.9633\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 70.6714\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 70.4568\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 81us/step - loss: 70.6402\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 70.6473\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 70.4345\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 70.9181\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 70.8366\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 81us/step - loss: 70.3768\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 70.8178\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 70.6957\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 70.7026\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 70.4963\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 70.6593\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 70.5810\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 70.6690\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 70.4204\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 82us/step - loss: 70.5300\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 70.2817\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 70.4195\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 82us/step - loss: 70.5489\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 70.2469\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 70.5921\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 70.4875\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 70.2723\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 70.6781\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 70.1967\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 70.6016\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 70.5316\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 83us/step - loss: 70.4011\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 70.2778\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 70.4288\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 70.5204\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 82us/step - loss: 70.4166\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 70.0039\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 70.2806\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 81us/step - loss: 70.2298\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 70.3689\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 82us/step - loss: 70.0180\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 81us/step - loss: 70.3851\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 70.4516\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 70.0954\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 85us/step - loss: 69.9087\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 70.1471\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 70.1093\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.9863\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 70.3942\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 70.3371\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 69.8836\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 70.2912\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 70.2381\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 70.2193\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 70.0327\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 82us/step - loss: 70.1759\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 70.1757\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 84us/step - loss: 70.2481\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 69.9661\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 70.1176\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.8505\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 69.9995\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 70.0814\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.8756\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 70.2029\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 70.0395\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 69.8785\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 70.2460\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 69.8588\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 70.2207\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 70.1172\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 84us/step - loss: 70.0167\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 69.9086\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 70.0220\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 70.1580\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 70.0488\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 81us/step - loss: 69.6810\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 83us/step - loss: 69.8901\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 69.8951\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 70.0304\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 69.6891\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 70.0674\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 70.0927\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 69.7962\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.5654\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 69.7771\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.8245\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 69.6464\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 83us/step - loss: 70.1044\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 82us/step - loss: 70.0195\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.5927\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 85us/step - loss: 69.9992\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 69.9096\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 69.8770\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 69.7182\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 81us/step - loss: 69.9402\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 69.8845\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 88us/step - loss: 69.9567\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.6832\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 83us/step - loss: 69.8239\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.5773\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 69.7277\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 69.7875\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.5967\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 69.9231\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 69.8138\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 69.5702\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 82us/step - loss: 69.9772\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 69.5808\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.9258\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 82us/step - loss: 69.8658\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 69.7813\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 85us/step - loss: 69.6382\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 69.7961\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.9514\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 69.7718\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 82us/step - loss: 69.4124\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 82us/step - loss: 69.7114\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 69.6430\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 84us/step - loss: 69.7640\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.4637\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 69.8064\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.8545\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 69.5719\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 69.3621\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.5868\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 85us/step - loss: 69.5931\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 82us/step - loss: 69.4496\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.8449\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 69.7848\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.4441\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 69.7850\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.6770\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 69.7086\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 69.5671\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 69.6737\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 69.7011\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 69.7292\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 69.5104\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.6690\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.3325\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.5397\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 69.5750\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.4664\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 69.7042\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.6381\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.4061\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 69.7827\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.3921\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 69.7726\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.7009\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.5727\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.5207\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.5763\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 69.7244\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.5963\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.2880\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.5064\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.4513\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.6720\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 69.2927\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.6655\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.7342\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 69.4124\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.2162\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.4338\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.4202\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.3042\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.7053\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.6571\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.2588\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 69.6043\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.5329\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.6159\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.3474\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 69.5645\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.5292\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.5859\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.3599\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.5053\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.2457\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.3911\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.4541\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.2966\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.6160\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.4878\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 69.2786\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.6894\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.2904\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.6294\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.5590\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.5089\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.3655\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.4668\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.6146\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.5245\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.1157\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.4111\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 69.3589\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 69.5175\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 69.1363\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.5458\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 69.6245\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 69.2814\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.0733\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.3264\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.3035\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.1906\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 69.5864\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.5404\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.1433\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 69.5129\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.4659\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 69.4114\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 69.2820\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.4188\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 69.4178\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.4574\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 69.2723\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.3893\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 69.1699\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.2742\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.3597\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.1856\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.4469\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.4116\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.2069\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.5709\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 69.1778\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.5408\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.4381\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.3868\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.2737\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 69.3902\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.5186\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 69.4364\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 69.0538\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.3171\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.2264\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 69.4521\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.0913\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.4773\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.4753\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.1929\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.0117\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.2439\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 69.2322\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.0923\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.5075\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.4350\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.0653\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 69.4061\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 69.3953\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 69.3764\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.1886\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.3695\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.3297\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 69.4587\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.1432\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 69.3339\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 69.0628\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.1990\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 69.3286\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.1012\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.4261\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.2764\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.0907\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.5400\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.0878\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 69.4671\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.3818\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.2703\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 69.2111\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.3335\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.4447\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.3635\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 68.9863\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.2319\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.2619\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.3247\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 68.9764\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.3906\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.4320\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.2005\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 68.9088\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 69.1509\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 69.2018\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.0513\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 69.4286\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.4300\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.0071\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.3859\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.3262\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.3119\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 69.1174\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 69.3136\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 69.2896\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 79us/step - loss: 69.3540\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 69.1666\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.2215\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 69.0089\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.2110\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.2548\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.0157\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.3613\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 69.2575\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.1076\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 69.4440\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.0113\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.4601\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.3306\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 80us/step - loss: 69.2822\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 69.1301\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.2431\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 69.3845\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 69.2940\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 68.9209\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 75us/step - loss: 69.2095\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 78us/step - loss: 69.1570\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 77us/step - loss: 69.3399\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 68.9956\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 69.3215\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 69.4073\n",
      "Epoch 1/1\n",
      " 7552/25000 [========>.....................] - ETA: 1s - loss: 69.0199"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-068a52a4d036>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                         shuffle=True)#,\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;31m#                    validation_data = (x_train, x_train))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1669\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1206\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1207\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for j in range(EPOCHS_AE):\n",
    "    for i in range(total_batch):\n",
    "        x_train = getBatchAE(i, BS_AE)\n",
    "        autoencoder.fit(x_train, x_train,\n",
    "                        epochs=1,\n",
    "                        batch_size=128,\n",
    "                        shuffle=True)#,\n",
    "    #                    validation_data = (x_train, x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     #______________________________________________________ link definition\n",
    "#     input_to_link = Input((1, img_rows, img_cols))\n",
    "#     ...several convolutions...\n",
    "#     link_model = Model(input=input_to_link, output=conv4)   # a chain is made of links\n",
    "\n",
    "#     #______________________________________________________ chain definition\n",
    "#     input_to_chain = Input((1, img_rows, img_cols))\n",
    "#     output_link_1 = link_model(input_to_chain)\n",
    "#     output_link_2 = link_model(output_link_1)\n",
    "#     chain_model = Model(input=input_to_chain, output=output_link_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T22:41:33.348999Z",
     "start_time": "2018-02-20T22:41:33.275407Z"
    }
   },
   "outputs": [],
   "source": [
    "link_model = Model(input_img, encoded4)\n",
    "input_1 = Input(shape=(769,))\n",
    "input_2 = Input(shape=(769,))\n",
    "output_link_1 = link_model(input_1)\n",
    "output_link_2 = link_model(input_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T20:18:15.597554Z",
     "start_time": "2018-02-20T20:18:15.489419Z"
    }
   },
   "outputs": [],
   "source": [
    "# Try it without training the two autoencoders first:\n",
    "input_img = (769,)\n",
    "dims = [600, 400, 200, 100]\n",
    "auto1 = Sequential()\n",
    "auto1.add(Dense(600, activation='selu',input_shape=input_img))\n",
    "for i in range(1,len(dims)):\n",
    "    auto1.add(Dense(dims[i], activation='selu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:18:16.047530Z",
     "start_time": "2018-02-20T21:18:15.750660Z"
    }
   },
   "outputs": [],
   "source": [
    "main_input = Input(shape=(769,), dtype='int32', name='main_input')\n",
    "x = Embedding(output_dim=600, input_dim=769)(main_input)\n",
    "# This embedding layer will encode the input sequence\n",
    "# into a sequence of dense 512-dimensional vectors.\n",
    "# x = Dense(600, activation='selu', input_shape = (769,))\n",
    "x = Dense(400, activation='selu')(x)\n",
    "x = Dense(200, activation='selu')(x)\n",
    "encode_out = Dense(100, activation='selu')(x)\n",
    "\n",
    "main_input2 = Input(shape=(769,), dtype='int32', name='main_input2')\n",
    "x = Embedding(output_dim=600, input_dim=769)(main_input2)\n",
    "# This embedding layer will encode the input sequence\n",
    "# into a sequence of dense 512-dimensional vectors.\n",
    "# x = Dense(600, activation='selu', input_shape = (769,))\n",
    "x = Dense(400, activation='selu')(x)\n",
    "x = Dense(200, activation='selu')(x)\n",
    "encode_out2 = Dense(100, activation='selu')(x)\n",
    "# A LSTM will transform the vector sequence into a single vector,\n",
    "# containing information about the entire sequence\n",
    "# lstm_out = LSTM(32)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T22:44:22.512392Z",
     "start_time": "2018-02-20T22:44:22.378224Z"
    }
   },
   "outputs": [],
   "source": [
    "# create the rest of the model\n",
    "# fc_dims = [200, 400, 200, 100]\n",
    "# fully_connected = Sequential()\n",
    "# fully_connected.add(Dense(fc_dims[i], activation='selu', input_shape = (200,)))\n",
    "# for i in range(1, len(fc_dims)):\n",
    "#     fully_connected.add(Dense(fc_dims[i], activation='selu'))\n",
    "# model = Model([auto1, auto1], fully_connected)\n",
    "x = keras.layers.concatenate([output_link_1, output_link_2])\n",
    "# x = Flatten()(x)\n",
    "x = Dense(400, activation='relu')(x)\n",
    "x = Dense(200, activation='relu')(x)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "main_output = Dense(2,  activation='softmax', name='main_output')(x)\n",
    "model = Model(inputs=[input_1, input_2], outputs=[main_output])\n",
    "model.compile(optimizer='adadelta', loss='categorical_crossentropy',  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:18:17.146599Z",
     "start_time": "2018-02-20T21:18:17.142594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"main_output_4/Softmax:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(main_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T01:13:30.537703Z",
     "start_time": "2018-02-21T00:24:52.881134Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Test loss: 0.34942051426410675\n",
      "Test accuracy: 0.82233\n",
      "1\n",
      "2\n",
      "3\n",
      "Test loss: 0.3405716425162554\n",
      "Test accuracy: 0.83292\n",
      "4\n",
      "5\n",
      "6\n",
      "Test loss: 0.3742014820575714\n",
      "Test accuracy: 0.81911\n",
      "7\n",
      "8\n",
      "9\n",
      "Test loss: 0.3544433444869518\n",
      "Test accuracy: 0.81185\n",
      "10\n",
      "11\n",
      "12\n",
      "Test loss: 0.34497075414180756\n",
      "Test accuracy: 0.82927\n",
      "13\n",
      "14\n",
      "15\n",
      "Test loss: 0.3963639073586464\n",
      "Test accuracy: 0.8077\n",
      "16\n",
      "17\n",
      "18\n",
      "Test loss: 0.3793555604600906\n",
      "Test accuracy: 0.81953\n",
      "19\n",
      "20\n",
      "21\n",
      "Test loss: 0.3812181893348694\n",
      "Test accuracy: 0.81862\n",
      "22\n",
      "23\n",
      "24\n",
      "Test loss: 0.40839160892009735\n",
      "Test accuracy: 0.79608\n",
      "25\n",
      "26\n",
      "27\n",
      "Test loss: 0.39549178974628446\n",
      "Test accuracy: 0.81541\n",
      "28\n",
      "29\n",
      "30\n",
      "Test loss: 0.3835984764158726\n",
      "Test accuracy: 0.80804\n",
      "31\n",
      "32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-4d0dbf90dd83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                         shuffle=True)#,\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;31m#                         validation_data = ([validation_test[:,0,:], validation_test[:,1,:]], [validation_test_l]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1669\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1206\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1207\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS_MLP = 1000\n",
    "TOTAL_MLP = 1000000\n",
    "BS_MLP = 25000\n",
    "total_batch = int(TOTAL_MLP/BS_MLP)\n",
    "for j in range(EPOCHS_MLP):\n",
    "    print(j)\n",
    "    whiteWins = np.random.permutation(whiteWins2[100000:])[:1000000]\n",
    "    blackWins = np.random.permutation(blackWins2[100000:])[:1000000]\n",
    "\n",
    "    for i in range(total_batch): \n",
    "        batch_xs, batch_ys = getBatchMLP(i*BS_MLP, BS_MLP)\n",
    "        model.fit([batch_xs[:,0,:],batch_xs[:,1,:]], [batch_ys],\n",
    "                        epochs=1,\n",
    "                        verbose=0,\n",
    "                        batch_size=128,\n",
    "                        shuffle=True)#,\n",
    "#                         validation_data = ([validation_test[:,0,:], validation_test[:,1,:]], [validation_test_l]))\n",
    "    if j % 3 == 0:\n",
    "        score = model.evaluate([validation_test[:,0,:], validation_test[:,1,:]], [validation_test_l], verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to create the encoders separately\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
